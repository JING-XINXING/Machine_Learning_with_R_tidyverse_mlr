# (Intercept) -933.51089980
# Year           0.54520628
# Rain0          0.35437389
# Temp1         -0.24375777
# Rain1         -0.71510665
# Temp2          0.04260419
# Rain2          1.94334596
# Temp3         -0.57082385
# Rain3          0.64227151
# Temp4         -0.48289549
lmCoefs <- coef(lm(Yield ~ ., data = iowaTib))
lmCoefs
# (Intercept)          Year         Rain0         Temp1         Rain1         Temp2
# -1.637276e+03  8.755817e-01  7.845010e-01 -4.597870e-01 -7.794070e-01  4.822053e-01
# Rain2         Temp3         Rain3         Temp4
# 2.556968e+00  4.890862e-02  4.078031e-01 -6.562937e-01
coefTib <- tibble(Coef = rownames(ridgeCoefs)[-1],
Ridge = as.vector(ridgeCoefs)[-1],
Lm = as.vector(lmCoefs)[-1])
head(coefTib)
# A tibble: 6 × 3
# Coef    Ridge     Lm
# <chr>   <dbl>  <dbl>
# 1 Year   0.545   0.876
# 2 Rain0  0.354   0.785
# 3 Temp1 -0.244  -0.460
# 4 Rain1 -0.715  -0.779
# 5 Temp2  0.0426  0.482
# 6 Rain2  1.94    2.56
coefUntidy <- gather(coefTib, key = Model, value = Beta, -Coef)
head(coefUntidy)
# A tibble: 6 × 3
# Coef  Model    Beta
# <chr> <chr>   <dbl>
# 1 Year  Ridge  0.545
# 2 Rain0 Ridge  0.354
# 3 Temp1 Ridge -0.244
# 4 Rain1 Ridge -0.715
# 5 Temp2 Ridge  0.0426
# 6 Rain2 Ridge  1.94
ggplot(coefUntidy, aes(reorder(Coef, Beta), Beta, fill = Model)) +
geom_bar(stat = "identity", col = "black") +
facet_wrap(~Model) +
theme_bw()  +
theme(legend.position = "none")
summary(coefUntidy)
visdat::vis_dat(coefUntidy)
# MAKE LASSO LEARNER ----
lasso <- makeLearner("regr.glmnet", alpha = 1, id = "lasso")
class(lasso)
# TUNING LAMBDA FOR LASSO ----
lassoParamSpace <- makeParamSet(
makeNumericParam("s", lower = 0, upper = 15))
parallelStartSocket(cpus = detectCores())
tunedLassoPars <- tuneParams(lasso, task = iowaTask, # ~30 sec
resampling = cvForTuning,
par.set = lassoParamSpace,
control = randSearch)
parallelStop()
tunedLassoPars
# PLOTTING THE RANDOM SEARCH ----
lassoTuningData <- generateHyperParsEffectData(tunedLassoPars)
plotHyperParsEffect(lassoTuningData, x = "s", y = "mse.test.mean",
plot.type = "line") +
theme_bw()
# TRAINING FINAL MODEL WITH TUNED HYPERPARAMETERS ----
tunedLasso <- setHyperPars(lasso, par.vals = tunedLassoPars$x)
tunedLassoModel <- train(tunedLasso, iowaTask)
# INTERPRETTING THE LASSO REGRESSION MODEL ----
lassoModelData <- getLearnerModel(tunedLassoModel)
# plot(lassoModelData, xvar = "lambda", label = TRUE)
# plot(lassoModelData, xvar = "norm", label = TRUE)
lassoCoefs <- coef(lassoModelData, s = tunedLassoPars$x$s)
lassoCoefs
# (Intercept) -1.330253e+03
# Year         7.226751e-01
# Rain0        1.745260e-01
# Temp1        .
# Rain1        .
# Temp2        .
# Rain2        1.930557e+00
# Temp3       -6.678213e-02
# Rain3        1.059965e-01
# Temp4       -4.319123e-01
coefTib$LASSO <- as.vector(lassoCoefs)[-1]
coefUntidy <- gather(coefTib, key = Model, value = Beta, -Coef)
ggplot(coefUntidy, aes(reorder(Coef, Beta), Beta, fill = Model)) +
geom_bar(stat = "identity", col = "black") +
facet_wrap(~ Model) +
theme_bw() +
theme(legend.position = "none")
# MAKE ELASTIC NET LEARNER ----
elastic <- makeLearner("regr.glmnet", id = "elastic")
class(elastic)
# TUNING LAMBDA AND ALPHA FOR ELASTIC NET ----
elasticParamSpace <- makeParamSet(makeNumericParam("s", lower = 0, upper = 10),
makeNumericParam("alpha", lower = 0, upper = 1))
randSearchElastic <- makeTuneControlRandom(maxit = 400)
parallelStartSocket(cpus = detectCores())
tunedElasticPars <- tuneParams(elastic,
task = iowaTask, # ~1 min
resampling = cvForTuning,
par.set = elasticParamSpace,
control = randSearchElastic)
parallelStop()
tunedElasticPars
# Tune result:
#   Op. pars: s=1.21; alpha=0.926
# mse.test.mean=89.3839095
elasticTuningData <- generateHyperParsEffectData(tunedElasticPars)
plotHyperParsEffect(elasticTuningData, x = "s", y = "alpha",
z = "mse.test.mean", interpolate = "regr.kknn",
plot.type = "heatmap") +
scale_fill_gradientn(colours = terrain.colors(5)) +
geom_point(x = tunedElasticPars$x$s, y = tunedElasticPars$x$alpha) +
theme_bw()
# TRAINING FINAL MODEL WITH TUNED HYPERPARAMETERS ----
tunedElastic <- setHyperPars(elastic, par.vals = tunedElasticPars$x)
tunedElasticModel <- train(tunedElastic, iowaTask)
# INTERPRETTING THE LASSO REGRESSION MODEL ----
elasticModelData <- getLearnerModel(tunedElasticModel)
# plot(elasticModelData, xvar = "lambda", label = TRUE)
# plot(elasticModelData, xvar = "norm", label = TRUE)
elasticCoefs <- coef(elasticModelData, s = tunedElasticPars$x$s)
coefTib$Elastic <- as.vector(elasticCoefs)[-1]
coefUntidy <- gather(coefTib, key = Model, value = Beta, -Coef)
ggplot(coefUntidy, aes(reorder(Coef, Beta), Beta, fill = Model)) +
geom_bar(stat = "identity", position = "dodge", col = "black") +
facet_wrap(~ Model) +
theme_bw()
head(coefUntidy)
dim(coefUntidy)
coefUntidy
# 3 Temp1 Ridge -0.244
# 4 Rain1 Ridge -0.715
# 5 Temp2 Ridge  0.0426
# 6 Rain2 Ridge  1.94
# 7 Temp3 Ridge -0.571
# 8 Rain3 Ridge  0.642
# 9 Temp4 Ridge -0.483
# 10 Year  Lm     0.876
# ℹ 26 more rows
# ℹ Use `print(n = ...)` to see more rows
ggplot(coefUntidy, aes(reorder(Coef, Beta), Beta, fill = Model)) +
geom_bar(stat = "identity", position = "dodge", col = "black") +
facet_wrap(~ Model) +
theme_bw()
rio::export(coefUntidy, file = "coefUntidy_Elastic_LASSO_LM_RIDGE.xlsx")
getwd()
dir()
rio::export(coefUntidy, file = "./CH11_REGULARIZATION/coefUntidy_Elastic_LASSO_LM_RIDGE.xlsx")
# BENCHMARKING EACH MODEL BUILDING PROCESS ----
# MAKE TUNING WRAPPERS
ridgeWrapper <- makeTuneWrapper(ridge, resampling = cvForTuning,
par.set = ridgeParamSpace,
control = randSearch)
lassoWrapper <- makeTuneWrapper(lasso, resampling = cvForTuning,
par.set = lassoParamSpace,
control = randSearch)
elasticWrapper <- makeTuneWrapper(elastic, resampling = cvForTuning,
par.set = elasticParamSpace,
control = randSearchElastic)
learners = list(ridgeWrapper, lassoWrapper, elasticWrapper, "regr.lm")
library(parallel)
library(parallelMap)
kFold3 <- makeResampleDesc("CV", iters = 3)
parallelStartSocket(cpus = detectCores())
bench <- benchmark(learners, iowaTask, kFold3)
parallelStop()
bench
install.packages("elastic")
install.packages("elasticnet")
# SOLUTIONS TO EXERCISES ----
# 1
ridgeParamSpaceExtended <- makeParamSet(makeNumericParam("s", lower = 0, upper = 50))
parallelStartSocket(cpus = detectCores())
tunedRidgeParsExtended <- tuneParams(ridge, task = iowaTask, # ~30 sec
resampling = cvForTuning,
par.set = ridgeParamSpaceExtended,
control = randSearch)
parallelStop()
ridgeTuningDataExtended <- generateHyperParsEffectData(
tunedRidgeParsExtended)
plotHyperParsEffect(ridgeTuningDataExtended, x = "s", y = "mse.test.mean",
plot.type = "line") +
theme_bw()
# 2
coefTibInts <- tibble(Coef = rownames(ridgeCoefs),
Ridge = as.vector(ridgeCoefs),
Lm = as.vector(lmCoefs))
coefUntidyInts <- gather(coefTibInts, key = Model, value = Beta, -Coef)
dim(coefUntidyInts)
coefUntidyInts
# 11 (Intercept) Lm    -1637.
# 12 Year        Lm        0.876
# 13 Rain0       Lm        0.785
# 14 Temp1       Lm       -0.460
# 15 Rain1       Lm       -0.779
# 16 Temp2       Lm        0.482
# 17 Rain2       Lm        2.56
# 18 Temp3       Lm        0.0489
# 19 Rain3       Lm        0.408
# 20 Temp4       Lm       -0.656
ggplot(coefUntidyInts, aes(reorder(Coef, Beta), Beta, fill = Model)) +
geom_bar(stat = "identity", col = "black") +
facet_wrap(~Model) +
theme_bw()  +
theme(legend.position = "none")
# 3
plotHyperParsEffect(elasticTuningData, x = "s", y = "alpha",
z = "mse.test.mean", interpolate = "regr.kknn",
plot.type = "contour", show.experiments = TRUE) +
scale_fill_gradientn(colours = terrain.colors(5)) +
geom_point(x = tunedElasticPars$x$s, y = tunedElasticPars$x$alpha) +
theme_bw()
plotHyperParsEffect(elasticTuningData, x = "s", y = "alpha",
z = "mse.test.mean", plot.type = "scatter") +
theme_bw()
# 4
ggplot(coefUntidy, aes(reorder(Coef, Beta), Beta, fill = Model)) +
geom_bar(stat = "identity", position = "dodge", col = "black") +
theme_bw()
# 5
yieldOnly <- select(iowaTib, Yield)
head(yieldOnly)
yieldOnlyTask <- makeRegrTask(data = yieldOnly, target = "Yield")
lassoStrict <- makeLearner("regr.glmnet", lambda = 500)
loo <- makeResampleDesc("LOO")
resample("regr.lm", yieldOnlyTask, loo)
#
# Aggregated Result: mse.test.mean=179.3427539
#
# Resample Result
# Task: yieldOnly
# Learner: regr.lm
# Aggr perf: mse.test.mean=179.3427539
# Runtime: 0.0495861
resample(lassoStrict, iowaTask, loo)
# 6
install.packages("plotmo")
library(plotmo)
# Loading required package: Formula
# Loading required package: plotrix
# Loading required package: TeachingDemos
plotres(elasticModelData)
plotres(ridgeModelData)
plotres(lassoModelData)
head(lassoStrict)
install.packages("mlr3")
install.packages("rio")
library(rio)
install_formats()
# LOAD PACKAGES ----
library(mlr)
library(tidyverse)
# LOAD DATA ----
data(Ozone, package = "mlbench")
ozoneTib <- as_tibble(Ozone)
names(ozoneTib) <- c("Month", "Date", "Day", "Ozone", "Press_height",
"Wind", "Humid", "Temp_Sand", "Temp_Monte",
"Inv_height", "Press_grad", "Inv_temp", "Visib")
ozoneTib
ozoneClean <- mutate_all(ozoneTib, as.numeric) %>%
filter(is.na(Ozone) == FALSE)
ozoneClean
# PLOT DATA ----
ozoneUntidy <- gather(ozoneClean, key = "Variable", value = "Value", -Ozone)
ozoneUntidy
ggplot(ozoneUntidy, aes(Value, Ozone)) +
facet_wrap(~ Variable, scale = "free_x") +
geom_point() +
geom_smooth() +
geom_smooth(method = "lm", col = "red") +
theme_bw()
# IMPUTE MISSING VALUES ----
?imputations
imputeMethod <- imputeLearner("regr.rpart")
ozoneImp <- impute(as.data.frame(ozoneClean),
classes = list(numeric = imputeMethod))
# MAKE TASK AND LEARNER ----
ozoneTask <- makeRegrTask(data = ozoneImp$data, target = "Ozone")
lin <- makeLearner("regr.lm")
# FEATURE SELECTION FILTER METHOD ----
#install.packages("FSelector")
listFilterMethods()
filterVals <- generateFilterValuesData(ozoneTask,
method = "linear.correlation")
filterVals$data
plotFilterValues(filterVals) + theme_bw()
# FILTER WRAPPER ----
filterWrapper <- makeFilterWrapper(learner = lin,
fw.method = "linear.correlation")
lmParamSpace <- makeParamSet(
makeIntegerParam("fw.abs", lower = 1, upper = 12)
)
gridSearch <- makeTuneControlGrid()
kFold <- makeResampleDesc("CV", iters = 10)
tunedFeats <- tuneParams(filterWrapper, task = ozoneTask, resampling = kFold,
par.set = lmParamSpace, control = gridSearch)
tunedFeats
# MAKE NEW TASK AND TRAIN MODEL FOR FILTER METHOD ----
filteredTask <- filterFeatures(ozoneTask, fval = filterVals,
abs = unlist(tunedFeats$x))
filteredModel <- train(lin, filteredTask)
# FEATURE SELECTION WRAPPER METHOD ----
featSelControl <- makeFeatSelControlSequential(method = "sfbs")
selFeats <- selectFeatures(learner = lin, task = ozoneTask,
resampling = kFold, control = featSelControl)
selFeats
# MAKE NEW TASK AND TRAIN MODEL FOR THE WRAPPER METHOD ----
ozoneSelFeat <- ozoneImp$data[, c("Ozone", selFeats$x)]
ozoneSelFeatTask <- makeRegrTask(data = ozoneSelFeat, target = "Ozone")
wrapperModel <- train(lin, ozoneSelFeatTask)
# MAKE IMPUTATION WRAPPER FOR CROSS-VALIDATION ----
imputeMethod <- imputeLearner("regr.rpart")
imputeWrapper <- makeImputeWrapper(lin,
classes = list(numeric = imputeMethod))
# MAKE FEATURE SELECTION WRAPPER FOR CROSS-VALIDATION ----
featSelControl <- makeFeatSelControlSequential(method = "sfbs")
featSelWrapper <- makeFeatSelWrapper(learner = imputeWrapper,
resampling = kFold,
control = featSelControl)
# CROSS-VALIDATE MODEL BUILDING PROCESS ----
library(parallel)
library(parallelMap)
ozoneTaskWithNAs <- makeRegrTask(data = ozoneClean, target = "Ozone")
kFold3 <- makeResampleDesc("CV", iters = 3)
parallelStartSocket(cpus = detectCores())
lmCV <- resample(featSelWrapper, ozoneTaskWithNAs, resampling = kFold3) #~ 1.5 min
parallelStop()
lmCV
# LOOK AT MODEL DIAGNOSTICS ----
wrapperModelData <- getLearnerModel(wrapperModel)
summary(wrapperModelData)
par(mfrow = c(2, 2))
plot(wrapperModelData)
par(mfrow = c(1, 1))
# SOLUTIONS TO EXERCISES ----
# 1
filterValsForest <- generateFilterValuesData(ozoneTask,
method = "randomForestSRC_importance")
getwd()
# LOAD PACKAGES ----
library(mlr)
dir()
dir.create("CH09_LINEAR_REGRESSION")
setwd()
setwd("CH09_LINEAR_REGRESSION")
# LOAD PACKAGES ----
library(mlr)
library(tidyverse)
# LOAD DATA ----
data(Ozone, package = "mlbench")
ozoneTib <- as_tibble(Ozone)
names(ozoneTib) <- c("Month", "Date", "Day", "Ozone", "Press_height",
"Wind", "Humid", "Temp_Sand", "Temp_Monte",
"Inv_height", "Press_grad", "Inv_temp", "Visib")
ozoneTib
dim(ozoneTib)
visdat::vis_dat(ozoneTib)
?mutate_all
ozoneClean <- mutate_all(ozoneTib, as.numeric) %>%
filter(is.na(Ozone) == FALSE)
ozoneClean
visdat::vis_dat(ozoneClean)
# 5     1     5     1     5         5760     3    51        54       45.3       1450         25     57.0
# 6     1     6     2     6         5720     4    69        35       49.6       1568         15     53.8
# 7     1     7     3     4         5790     6    19        45       46.4       2631        -33     54.1
# 8     1     8     4     4         5790     3    25        55       52.7        554        -28     64.8
# 9     1     9     5     6         5700     3    73        41       48.0       2083         23     52.5
# 10     1    10     6     7         5700     3    59        44       NA         2654         -2     48.4
# ℹ 351 more rows
# ℹ 1 more variable: Visib <dbl>
# ℹ Use `print(n = ...)` to see more rows
# PLOT DATA ----
ozoneUntidy <- gather(ozoneClean, key = "Variable", value = "Value", -Ozone)
ozoneUntidy
visdat::vis_dat(ozoneUntidy)
# 3     3 Month        1
# 4     5 Month        1
# 5     5 Month        1
# 6     6 Month        1
# 7     4 Month        1
# 8     4 Month        1
# 9     6 Month        1
# 10     7 Month        1
# ℹ 4,322 more rows
# ℹ Use `print(n = ...)` to see more rows
ggplot(ozoneUntidy, aes(Value, Ozone)) +
facet_wrap(~ Variable, scale = "free_x") +
geom_point() +
geom_smooth() +
geom_smooth(method = "lm", col = "red") +
theme_bw()
# 3     3 Month        1
# 4     5 Month        1
# 5     5 Month        1
# 6     6 Month        1
# 7     4 Month        1
# 8     4 Month        1
# 9     6 Month        1
# 10     7 Month        1
# ℹ 4,322 more rows
# ℹ Use `print(n = ...)` to see more rows
ggplot(ozoneUntidy, aes(Value, Ozone)) +
facet_wrap(~ Variable, scale = "free_x") +
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth() +
geom_smooth(method = "lm", col = "red") +
theme_bw()
# IMPUTE MISSING VALUES ----
?imputations
imputeMethod <- imputeLearner("regr.rpart")
ozoneImp <- impute(as.data.frame(ozoneClean),
classes = list(numeric = imputeMethod))
source("~/R_Space/Machine_Learning_with_R_tidyverse_mlr/59e95a4689eeb92f380f4ab2_202105_394e9018-b221-11eb-aa12-00163e0a088c_ML_R_tidyverse_mlr_code/CH09_LINEAR_REGRESSION.R", echo=TRUE)
ozoneImp
visdat::vis_dat(ozoneImp)
visdat::vis_dat(ozoneImp$data)
# MAKE TASK AND LEARNER ----
ozoneTask <- makeRegrTask(data = ozoneImp$data, target = "Ozone")
class(ozoneTask)
lin <- makeLearner("regr.lm")
class(lin)
# FEATURE SELECTION FILTER METHOD ----
#install.packages("FSelector")
listFilterMethods()
filterVals <- generateFilterValuesData(ozoneTask,
method = "linear.correlation")
filterVals$data
# 3:          Day numeric linear.correlation 0.04151444
# 4: Press_height numeric linear.correlation 0.58752354
# 5:         Wind numeric linear.correlation 0.00468138
# 6:        Humid numeric linear.correlation 0.45148094
# 7:    Temp_Sand numeric linear.correlation 0.76977674
# 8:   Temp_Monte numeric linear.correlation 0.74159034
# 9:   Inv_height numeric linear.correlation 0.57563391
# 10:   Press_grad numeric linear.correlation 0.23331823
# 11:     Inv_temp numeric linear.correlation 0.72712691
# 12:        Visib numeric linear.correlation 0.41471463
plotFilterValues(filterVals) + theme_bw()
?theme
# 3:          Day numeric linear.correlation 0.04151444
# 4: Press_height numeric linear.correlation 0.58752354
# 5:         Wind numeric linear.correlation 0.00468138
# 6:        Humid numeric linear.correlation 0.45148094
# 7:    Temp_Sand numeric linear.correlation 0.76977674
# 8:   Temp_Monte numeric linear.correlation 0.74159034
# 9:   Inv_height numeric linear.correlation 0.57563391
# 10:   Press_grad numeric linear.correlation 0.23331823
# 11:     Inv_temp numeric linear.correlation 0.72712691
# 12:        Visib numeric linear.correlation 0.41471463
plotFilterValues(filterVals) + theme_bw() + theme(axis.text.x = element_text(angle = 90))
# FILTER WRAPPER ----
filterWrapper <- makeFilterWrapper(learner = lin,
fw.method = "linear.correlation")
lmParamSpace <- makeParamSet(
makeIntegerParam("fw.abs", lower = 1, upper = 12)
)
gridSearch <- makeTuneControlGrid()
kFold <- makeResampleDesc("CV", iters = 10)
tunedFeats <- tuneParams(filterWrapper, task = ozoneTask, resampling = kFold,
par.set = lmParamSpace, control = gridSearch)
tunedFeats
# MAKE NEW TASK AND TRAIN MODEL FOR FILTER METHOD ----
filteredTask <- filterFeatures(ozoneTask, fval = filterVals,
abs = unlist(tunedFeats$x))
filteredModel <- train(lin, filteredTask)
# FEATURE SELECTION WRAPPER METHOD ----
featSelControl <- makeFeatSelControlSequential(method = "sfbs")
selFeats <- selectFeatures(learner = lin,
task = ozoneTask,
resampling = kFold,
control = featSelControl)
selFeats
# MAKE NEW TASK AND TRAIN MODEL FOR THE WRAPPER METHOD ----
ozoneSelFeat <- ozoneImp$data[, c("Ozone", selFeats$x)]
ozoneSelFeatTask <- makeRegrTask(data = ozoneSelFeat, target = "Ozone")
wrapperModel <- train(lin, ozoneSelFeatTask)
# MAKE IMPUTATION WRAPPER FOR CROSS-VALIDATION ----
imputeMethod <- imputeLearner("regr.rpart")
imputeWrapper <- makeImputeWrapper(lin,
classes = list(numeric = imputeMethod))
# MAKE FEATURE SELECTION WRAPPER FOR CROSS-VALIDATION ----
featSelControl <- makeFeatSelControlSequential(method = "sfbs")
featSelWrapper <- makeFeatSelWrapper(learner = imputeWrapper,
resampling = kFold,
control = featSelControl)
# CROSS-VALIDATE MODEL BUILDING PROCESS ----
library(parallel)
library(parallelMap)
ozoneTaskWithNAs <- makeRegrTask(data = ozoneClean, target = "Ozone")
kFold3 <- makeResampleDesc("CV", iters = 3)
parallelStartSocket(cpus = detectCores())
lmCV <- resample(featSelWrapper, ozoneTaskWithNAs, resampling = kFold3) #~ 1.5 min
parallelStop()
lmCV
# LOOK AT MODEL DIAGNOSTICS ----
wrapperModelData <- getLearnerModel(wrapperModel)
summary(wrapperModelData)
par(mfrow = c(2, 2))
plot(wrapperModelData)
par(mfrow = c(1, 1))
# SOLUTIONS TO EXERCISES ----
# 1
filterValsForest <- generateFilterValuesData(ozoneTask,
method = "randomForestSRC_importance")
filterValsForest$data
# SOLUTIONS TO EXERCISES ----
# 1
filterValsForest <- generateFilterValuesData(ozoneTask,
method = "randomForestSRC_importance")
